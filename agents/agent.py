from utils.query import Model, query
from utils.utils import stopwatch

# TODO: Make sure that the request is also added to the message history.
# TODO: Implement support for multiple models (use enum)

class Agent:
	"""Class to represent an agent.

	#### Attributes
		
	message (array(str)): An array of dialoges. Each dialoge contains information about the role of the sender (either 'user' or 'assistant', which is the agent itself) and the content of the message as a key-value pair.

	model (Model): A enum type that identifies what model should be used.

	#### Methods

	update_message (array(str)) -> None: Takes an array of message(s) and adds it to the message attribute so the most updated dialogue history can be passed in every query.

	evaluate -> str: Makes an API call to the respective LLM, as specified by the argument.
	"""

	def __init__(self, model: Model):
		self.message = []
		self.model = model

	def update_message(self, message: str):
		"""Updates message to keep track of the entire conversation.

		#### Args

		message (array(str)): The message intended to be added to the conversation history. The message should be an array of dialoges, could be just a single element, and should be in the JSON format so it can be parsed by the agent.
		"""
		for dialog in message:
			self.message.append(dialog)
      
	@stopwatch
	def evaluate(self):
		"""Makes API call to respective LLM model with error handling. Automatically appends the response to message history.

		#### Args
			
		model (Model): The LLM model to use for generating responses.

		#### Returns
		
		str: The .json response generated by the model.
		"""

		response = query(model = self.model, message = self.message, type = self.__class__.__name__)
		
		return response